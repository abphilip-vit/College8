{
 "cells": [
  {
   "source": [
    "# Allen Ben Philipose - 18BIS0043\n",
    "#### Lab FAT, L53+L54\n",
    "#### ECE3502 - IoT Domain Analyst\n",
    "#### Submitted to: Prof. Pradheep T"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Aim\n",
    "\n",
    "In the given dataset, use random forest and predict the number of cases for \n",
    "- 01.03.2021,Belgium (Reg.No: 18BIS0043)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Algorithm Explanation\n",
    "\n",
    "Random forests, or random decision forests, are an ensemble learning technique for classification, regression, and other tasks. It works by training a large number of decision trees and then outputing the class that is the mode of the classes (classification) or the mean/average prediction (regression) of the individual trees. Random decision forests compensate for decision trees' inclination for excessive fit to their training set. Although random forests surpass decision trees in practice, their accuracy is lower than that of gradient boosted trees. However, the features of the data might have an effect on their performance.\n",
    "\n",
    "Each tree in the random forest generates a class prediction, and the class with the most votes becomes the prediction of our model. A large number of substantially uncorrelated models (trees) acting in conjunction outperforms any of the component models individually. A random forest is a meta estimator that fits a number of decision tree classifiers to different subsamples of the dataset and then utilises averaging to increase predicted accuracy and avoid overfitting.\n",
    "\n",
    "\"Random Forest is a classifier that combines many decision trees on diverse subsets of a given dataset and uses the average to increase the dataset's predicted accuracy.\" Rather of depending on a single decision tree, the random forest collects the forecasts from each tree and forecasts the final output based on the majority vote of forecasts. \n",
    "\n",
    "<br />\n",
    "\n",
    "*Info from documentations*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Code and Result"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "s9IvUwnBSCl2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, f1_score \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyP9iy-qZY4k"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen = pd.read_csv(\"Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      dateRep  day  month  year  cases  deaths countriesAndTerritories geoId  \\\n",
       "0  14-12-2020   14     12  2020    746       6             Afghanistan    AF   \n",
       "1  13-12-2020   13     12  2020    298       9             Afghanistan    AF   \n",
       "2  12-12-2020   12     12  2020    113      11             Afghanistan    AF   \n",
       "3  11-12-2020   11     12  2020     63      10             Afghanistan    AF   \n",
       "4  10-12-2020   10     12  2020    202      16             Afghanistan    AF   \n",
       "\n",
       "  countryterritoryCode  popData2019 continentExp  \\\n",
       "0                  AFG   38041757.0         Asia   \n",
       "1                  AFG   38041757.0         Asia   \n",
       "2                  AFG   38041757.0         Asia   \n",
       "3                  AFG   38041757.0         Asia   \n",
       "4                  AFG   38041757.0         Asia   \n",
       "\n",
       "   Cumulative_number_for_14_days_of_COVID-19_cases_per_100000  \n",
       "0                                           9.013779           \n",
       "1                                           7.052776           \n",
       "2                                           6.868768           \n",
       "3                                           7.134266           \n",
       "4                                           6.968658           "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dateRep</th>\n      <th>day</th>\n      <th>month</th>\n      <th>year</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>countriesAndTerritories</th>\n      <th>geoId</th>\n      <th>countryterritoryCode</th>\n      <th>popData2019</th>\n      <th>continentExp</th>\n      <th>Cumulative_number_for_14_days_of_COVID-19_cases_per_100000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14-12-2020</td>\n      <td>14</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>746</td>\n      <td>6</td>\n      <td>Afghanistan</td>\n      <td>AF</td>\n      <td>AFG</td>\n      <td>38041757.0</td>\n      <td>Asia</td>\n      <td>9.013779</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13-12-2020</td>\n      <td>13</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>298</td>\n      <td>9</td>\n      <td>Afghanistan</td>\n      <td>AF</td>\n      <td>AFG</td>\n      <td>38041757.0</td>\n      <td>Asia</td>\n      <td>7.052776</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12-12-2020</td>\n      <td>12</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>113</td>\n      <td>11</td>\n      <td>Afghanistan</td>\n      <td>AF</td>\n      <td>AFG</td>\n      <td>38041757.0</td>\n      <td>Asia</td>\n      <td>6.868768</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11-12-2020</td>\n      <td>11</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>63</td>\n      <td>10</td>\n      <td>Afghanistan</td>\n      <td>AF</td>\n      <td>AFG</td>\n      <td>38041757.0</td>\n      <td>Asia</td>\n      <td>7.134266</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10-12-2020</td>\n      <td>10</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>202</td>\n      <td>16</td>\n      <td>Afghanistan</td>\n      <td>AF</td>\n      <td>AFG</td>\n      <td>38041757.0</td>\n      <td>Asia</td>\n      <td>6.968658</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "allen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all rows except Europe\n",
    "\n",
    "allen1 = allen[(allen['continentExp'] != 'Europe')].index\n",
    "allen.drop(allen1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns except date, cases and country\n",
    "\n",
    "allen = allen.drop(['deaths','geoId','countryterritoryCode','popData2019','continentExp','Cumulative_number_for_14_days_of_COVID-19_cases_per_100000'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "87jf1rTUZL5C",
    "outputId": "5b060829-317b-425b-c5fb-c67c502aefb6"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        dateRep  day  month  year  cases countriesAndTerritories\n",
       "340  14-12-2020   14     12  2020    788                 Albania\n",
       "341  13-12-2020   13     12  2020    879                 Albania\n",
       "342  12-12-2020   12     12  2020    802                 Albania\n",
       "343  11-12-2020   11     12  2020    873                 Albania\n",
       "344  10-12-2020   10     12  2020    752                 Albania"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dateRep</th>\n      <th>day</th>\n      <th>month</th>\n      <th>year</th>\n      <th>cases</th>\n      <th>countriesAndTerritories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>340</th>\n      <td>14-12-2020</td>\n      <td>14</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>788</td>\n      <td>Albania</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>13-12-2020</td>\n      <td>13</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>879</td>\n      <td>Albania</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>12-12-2020</td>\n      <td>12</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>802</td>\n      <td>Albania</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>11-12-2020</td>\n      <td>11</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>873</td>\n      <td>Albania</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>10-12-2020</td>\n      <td>10</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>752</td>\n      <td>Albania</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "allen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdHNmBriIOo1",
    "outputId": "40f73c7c-244b-4025-a71c-f192c2431176"
   },
   "outputs": [],
   "source": [
    "l1 = preprocessing.LabelEncoder()\n",
    "f1 = l1.fit_transform(allen['countriesAndTerritories']) \n",
    "f1 = pd.DataFrame(data=f1, columns=['countriesAndTerritories'])\n",
    "allen['countriesAndTerritories'] = f1['countriesAndTerritories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Albania', 'Andorra', 'Armenia', 'Austria', 'Azerbaijan', 'Belarus', 'Belgium', 'Bosnia_and_Herzegovina', 'Bulgaria', 'Croatia', 'Cyprus', 'Czechia', 'Denmark', 'Estonia', 'Faroe_Islands', 'Finland', 'France', 'Georgia', 'Germany', 'Gibraltar', 'Greece', 'Guernsey', 'Holy_See', 'Hungary', 'Iceland', 'Ireland', 'Isle_of_Man', 'Italy', 'Jersey', 'Kosovo', 'Latvia', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Malta', 'Moldova', 'Monaco', 'Montenegro', 'Netherlands', 'North_Macedonia', 'Norway', 'Poland', 'Portugal', 'Romania', 'Russia', 'San_Marino', 'Serbia', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'Turkey', 'Ukraine', 'United_Kingdom']\n"
     ]
    }
   ],
   "source": [
    "print(list(l1.inverse_transform(range(0,55))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Belgium']\n"
     ]
    }
   ],
   "source": [
    "# Assigned Country\n",
    "\n",
    "print(list(l1.inverse_transform([6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        dateRep  day  month  year  cases  countriesAndTerritories\n",
       "340  14-12-2020   14     12  2020    788                      1.0\n",
       "341  13-12-2020   13     12  2020    879                      1.0\n",
       "342  12-12-2020   12     12  2020    802                      1.0\n",
       "343  11-12-2020   11     12  2020    873                      1.0\n",
       "344  10-12-2020   10     12  2020    752                      1.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dateRep</th>\n      <th>day</th>\n      <th>month</th>\n      <th>year</th>\n      <th>cases</th>\n      <th>countriesAndTerritories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>340</th>\n      <td>14-12-2020</td>\n      <td>14</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>788</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>13-12-2020</td>\n      <td>13</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>879</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>12-12-2020</td>\n      <td>12</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>802</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>11-12-2020</td>\n      <td>11</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>873</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>10-12-2020</td>\n      <td>10</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>752</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "allen.head()"
   ]
  },
  {
   "source": [
    "## Pre-processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen.dropna(subset = [\"cases\"], inplace=True)\n",
    "allen.dropna(subset = [\"day\"], inplace=True)\n",
    "allen.dropna(subset = [\"month\"], inplace=True)\n",
    "allen.dropna(subset = [\"year\"], inplace=True)\n",
    "allen.dropna(subset = [\"countriesAndTerritories\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        dateRep  day  month  year  cases  countriesAndTerritories\n",
       "340  14-12-2020   14     12  2020    788                      1.0\n",
       "341  13-12-2020   13     12  2020    879                      1.0\n",
       "342  12-12-2020   12     12  2020    802                      1.0\n",
       "343  11-12-2020   11     12  2020    873                      1.0\n",
       "344  10-12-2020   10     12  2020    752                      1.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dateRep</th>\n      <th>day</th>\n      <th>month</th>\n      <th>year</th>\n      <th>cases</th>\n      <th>countriesAndTerritories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>340</th>\n      <td>14-12-2020</td>\n      <td>14</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>788</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>13-12-2020</td>\n      <td>13</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>879</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>12-12-2020</td>\n      <td>12</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>802</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>11-12-2020</td>\n      <td>11</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>873</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>10-12-2020</td>\n      <td>10</td>\n      <td>12</td>\n      <td>2020</td>\n      <td>752</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "allen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crrlZyeK1vU3"
   },
   "source": [
    "## Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "1E6I2IpxL96L",
    "outputId": "1f5af59a-a5b5-49c9-d719-ccc7994d2005"
   },
   "outputs": [],
   "source": [
    "x = allen.drop(['dateRep','cases'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxQC2ml5MoTr",
    "outputId": "c3728f42-261d-48be-b1d5-6b02349892ed"
   },
   "outputs": [],
   "source": [
    "y = allen['cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "-hUABKPIMvwE"
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=21)"
   ]
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = RandomForestClassifier()\n",
    "model0.fit(xtrain,ytrain)\n",
    "p0 = model0.predict(xtest)"
   ]
  },
  {
   "source": [
    "## Prediction (18BIS0043)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen2 = pd.DataFrame(columns=['day','month','year','countriesAndTerritories','cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {\"day\": 1, \n",
    "          \"month\": 3,\n",
    "          \"year\": 2021,\n",
    "          \"countriesAndTerritories\": 6,\n",
    "          \"cases\": 34,\n",
    "}\n",
    "allen2 = allen2.append(values, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model0.predict(allen2.drop(['cases'],axis=1))\n",
    "allen2['cases']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  day month  year countriesAndTerritories  cases\n",
       "0   1     3  2021                       6      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>day</th>\n      <th>month</th>\n      <th>year</th>\n      <th>countriesAndTerritories</th>\n      <th>cases</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>2021</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "allen2.head()"
   ]
  },
  {
   "source": [
    "# Inferences\n",
    "\n",
    "Using the given dataset, we have successfully classified the users based on their shopping patterns to predict the Online Shopping websites they use. The classification model is based on the ML Algorithm - **Decision Tree** with accuracies upto 36%. Availability of training data, and its quality is the primary reason that determines the accuracy. Lower dataset quality indirectly implies a lower accuracy for the model.\n",
    "\n",
    "We have also taken the example of a female user, 34 years old with a spending amount of Rs. 4900, and predicted the online shopping website as \"NYKAA\" based on the learning from the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE: 703709.70828\n"
     ]
    }
   ],
   "source": [
    "m = mean_squared_error(ytest,model0.predict(xtest))\n",
    "print(\"MSE: %.5f\"%m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-ac21be77b200>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m721\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'weighted avg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1979\u001b[1;33m         \u001b[0mname_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1980\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1981\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{:>{width}s} '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' {:>9}'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'weighted avg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1979\u001b[1;33m         \u001b[0mname_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1980\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1981\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{:>{width}s} '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' {:>9}'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest.values.ravel(),p0,target_names=range(0,721)))"
   ]
  },
  {
   "source": [
    "# Viva\n",
    "\n",
    "Which ML algorithm is the most effective for this application given the same dataset. Justify your choice of ML algorithm."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "-9qxQPoaNxsw"
   },
   "outputs": [],
   "source": [
    "model1 = RandomForestClassifier()\n",
    "model1.fit(xtrain,ytrain)\n",
    "p1 = model1.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQK3hbNx3w5g",
    "outputId": "e82b34ce-dc79-4f25-a59a-dffef18d9306"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[103   1   2 ...   0   0   0]\n [  8   3   0 ...   0   0   0]\n [  3   5   0 ...   0   0   0]\n ...\n [  0   0   0 ...   0   0   0]\n [  0   0   0 ...   0   0   0]\n [  0   0   0 ...   0   1   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(ytest,p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   0.00         0\n         355       0.00      0.00      0.00         0\n         356       0.00      0.00      0.00         1\n         357       0.00      0.00      0.00         0\n         358       0.00      0.00      0.00         0\n         359       0.00      0.00      0.00         0\n         360       0.00      0.00      0.00         2\n         361       0.00      0.00      0.00         1\n         362       0.00      0.00      0.00         1\n         363       0.00      0.00      0.00         0\n         364       0.00      0.00      0.00         1\n         365       0.00      0.00      0.00         0\n         366       0.00      0.00      0.00         0\n         367       0.00      0.00      0.00         1\n         368       0.00      0.00      0.00         0\n         369       0.00      0.00      0.00         1\n         370       0.00      0.00      0.00         1\n         371       0.00      0.00      0.00         1\n         372       0.00      0.00      0.00         1\n         373       0.00      0.00      0.00         0\n         374       0.00      0.00      0.00         0\n         375       0.00      0.00      0.00         1\n         376       0.00      0.00      0.00         0\n         377       0.00      0.00      0.00         1\n         378       0.00      0.00      0.00         1\n         379       0.00      0.00      0.00         1\n         380       0.00      0.00      0.00         1\n         381       0.00      0.00      0.00         1\n         382       0.00      0.00      0.00         0\n         383       0.00      0.00      0.00         0\n         384       0.00      0.00      0.00         0\n         385       0.00      0.00      0.00         0\n         386       0.00      0.00      0.00         1\n         387       0.00      0.00      0.00         0\n         388       0.00      0.00      0.00         0\n         389       0.00      0.00      0.00         1\n         390       0.00      0.00      0.00         1\n         391       0.00      0.00      0.00         0\n         392       0.00      0.00      0.00         1\n         393       0.00      0.00      0.00         1\n         394       0.00      0.00      0.00         2\n         395       0.00      0.00      0.00         1\n         396       0.00      0.00      0.00         1\n         397       0.00      0.00      0.00         1\n         398       0.00      0.00      0.00         1\n         399       0.00      0.00      0.00         1\n         400       0.00      0.00      0.00         0\n         401       0.00      0.00      0.00         0\n         402       0.00      0.00      0.00         0\n         403       0.00      0.00      0.00         2\n         404       0.00      0.00      0.00         0\n         405       0.00      0.00      0.00         0\n         406       0.00      0.00      0.00         1\n         407       0.00      0.00      0.00         1\n         408       0.00      0.00      0.00         1\n         409       0.00      0.00      0.00         0\n         410       0.00      0.00      0.00         0\n         411       0.00      0.00      0.00         1\n         412       0.00      0.00      0.00         1\n         413       0.00      0.00      0.00         0\n         414       0.00      0.00      0.00         0\n         415       0.00      0.00      0.00         0\n         416       0.00      0.00      0.00         0\n         417       0.00      0.00      0.00         0\n         418       0.00      0.00      0.00         1\n         419       0.00      0.00      0.00         0\n         420       0.00      0.00      0.00         0\n         421       0.00      0.00      0.00         1\n         422       0.00      0.00      0.00         1\n         423       0.00      0.00      0.00         0\n         424       0.00      0.00      0.00         0\n         425       0.00      0.00      0.00         1\n         426       0.00      0.00      0.00         0\n         427       0.00      0.00      0.00         0\n         428       0.00      0.00      0.00         0\n         429       0.00      0.00      0.00         1\n         430       0.00      0.00      0.00         0\n         431       0.00      0.00      0.00         1\n         432       0.00      0.00      0.00         0\n         433       0.00      0.00      0.00         0\n         434       0.00      0.00      0.00         0\n         435       0.00      0.00      0.00         0\n         436       0.00      0.00      0.00         1\n         437       0.00      0.00      0.00         1\n         438       0.00      0.00      0.00         1\n         439       0.00      0.00      0.00         1\n         440       0.00      0.00      0.00         1\n         441       0.00      0.00      0.00         1\n         442       0.00      0.00      0.00         1\n         443       0.00      0.00      0.00         0\n         444       0.00      0.00      0.00         1\n         445       0.00      0.00      0.00         0\n         446       0.00      0.00      0.00         1\n         447       0.00      0.00      0.00         1\n         448       0.00      0.00      0.00         1\n         449       0.00      0.00      0.00         0\n         450       0.00      0.00      0.00         0\n         451       0.00      0.00      0.00         0\n         452       0.00      0.00      0.00         0\n         453       0.00      0.00      0.00         0\n         454       0.00      0.00      0.00         2\n         455       0.00      0.00      0.00         1\n         456       0.00      0.00      0.00         0\n         457       0.00      0.00      0.00         2\n         458       0.00      0.00      0.00         1\n         459       0.00      0.00      0.00         0\n         460       0.00      0.00      0.00         0\n         461       0.00      0.00      0.00         0\n         462       0.00      0.00      0.00         1\n         463       0.00      0.00      0.00         0\n         464       0.00      0.00      0.00         0\n         465       0.00      0.00      0.00         0\n         466       0.00      0.00      0.00         0\n         467       0.00      0.00      0.00         1\n         468       0.00      0.00      0.00         1\n         469       0.00      0.00      0.00         0\n         470       0.00      0.00      0.00         0\n         471       0.00      0.00      0.00         1\n         472       0.00      0.00      0.00         0\n         473       0.00      0.00      0.00         1\n         474       0.00      0.00      0.00         1\n         475       0.00      0.00      0.00         1\n         476       0.00      0.00      0.00         0\n         477       0.00      0.00      0.00         1\n         478       0.00      0.00      0.00         0\n         479       0.00      0.00      0.00         1\n         480       0.00      0.00      0.00         1\n         481       0.00      0.00      0.00         1\n         482       0.00      0.00      0.00         0\n         483       0.00      0.00      0.00         1\n         484       0.00      0.00      0.00         1\n         485       0.00      0.00      0.00         1\n         486       0.00      0.00      0.00         0\n         487       0.00      0.00      0.00         0\n         488       0.00      0.00      0.00         0\n         489       0.00      0.00      0.00         0\n         490       0.00      0.00      0.00         1\n         491       0.00      0.00      0.00         0\n         492       0.00      0.00      0.00         1\n         493       0.00      0.00      0.00         1\n         494       0.00      0.00      0.00         1\n         495       0.00      0.00      0.00         1\n         496       0.00      0.00      0.00         1\n         497       0.00      0.00      0.00         0\n         498       0.00      0.00      0.00         1\n         499       0.00      0.00      0.00         0\n         500       0.00      0.00      0.00         1\n         501       0.00      0.00      0.00         0\n         502       0.00      0.00      0.00         1\n         503       0.00      0.00      0.00         0\n         504       0.00      0.00      0.00         0\n         505       0.00      0.00      0.00         1\n         506       0.00      0.00      0.00         1\n         507       0.00      0.00      0.00         0\n         508       0.00      0.00      0.00         1\n         509       0.00      0.00      0.00         1\n         510       0.00      0.00      0.00         1\n         511       0.00      0.00      0.00         0\n         512       0.00      0.00      0.00         0\n         513       0.00      0.00      0.00         0\n         514       0.00      0.00      0.00         0\n         515       0.00      0.00      0.00         1\n         516       0.00      0.00      0.00         1\n         517       0.00      0.00      0.00         1\n         518       0.00      0.00      0.00         0\n         519       0.00      0.00      0.00         0\n         520       0.00      0.00      0.00         0\n         521       0.00      0.00      0.00         0\n         522       0.00      0.00      0.00         0\n         523       0.00      0.00      0.00         0\n         524       0.00      0.00      0.00         0\n         525       0.00      0.00      0.00         1\n         526       0.00      0.00      0.00         1\n         527       0.00      0.00      0.00         1\n         528       0.00      0.00      0.00         1\n         529       0.00      0.00      0.00         0\n         530       0.00      0.00      0.00         1\n         531       0.00      0.00      0.00         0\n         532       0.00      0.00      0.00         1\n         533       0.00      0.00      0.00         0\n         534       0.00      0.00      0.00         1\n         535       0.00      0.00      0.00         0\n         536       0.00      0.00      0.00         1\n         537       0.00      0.00      0.00         1\n         538       0.00      0.00      0.00         0\n         539       0.00      0.00      0.00         1\n         540       0.00      0.00      0.00         0\n         541       0.00      0.00      0.00         1\n         542       0.00      0.00      0.00         1\n         543       0.00      0.00      0.00         1\n         544       0.00      0.00      0.00         0\n         545       0.00      0.00      0.00         1\n         546       0.00      0.00      0.00         1\n         547       0.00      0.00      0.00         0\n         548       0.00      0.00      0.00         0\n         549       0.00      0.00      0.00         2\n         550       0.00      0.00      0.00         0\n         551       0.00      0.00      0.00         0\n         552       0.00      0.00      0.00         0\n         553       0.00      0.00      0.00         0\n         554       0.00      0.00      0.00         1\n         555       0.00      0.00      0.00         1\n         556       0.00      0.00      0.00         1\n         557       0.00      0.00      0.00         0\n         558       0.00      0.00      0.00         1\n         559       0.00      0.00      0.00         0\n         560       0.00      0.00      0.00         0\n         561       0.00      0.00      0.00         1\n         562       0.00      0.00      0.00         1\n         563       0.00      0.00      0.00         0\n         564       0.00      0.00      0.00         0\n         565       0.00      0.00      0.00         1\n         566       0.00      0.00      0.00         0\n         567       0.00      0.00      0.00         1\n         568       0.00      0.00      0.00         1\n         569       0.00      0.00      0.00         1\n         570       0.00      0.00      0.00         0\n         571       0.00      0.00      0.00         1\n         572       0.00      0.00      0.00         1\n         573       0.00      0.00      0.00         0\n         574       0.00      0.00      0.00         1\n         575       0.00      0.00      0.00         1\n         576       0.00      0.00      0.00         1\n         577       0.00      0.00      0.00         0\n         578       0.00      0.00      0.00         0\n         579       0.00      0.00      0.00         1\n         580       0.00      0.00      0.00         0\n         581       0.00      0.00      0.00         2\n         582       0.00      0.00      0.00         0\n         583       0.00      0.00      0.00         1\n         584       0.00      0.00      0.00         1\n         585       0.00      0.00      0.00         0\n         586       0.00      0.00      0.00         0\n         587       0.00      0.00      0.00         1\n         588       0.00      0.00      0.00         0\n         589       0.00      0.00      0.00         0\n         590       0.00      0.00      0.00         1\n         591       0.00      0.00      0.00         0\n         592       0.00      0.00      0.00         1\n         593       0.00      0.00      0.00         1\n         594       0.00      0.00      0.00         1\n         595       0.00      0.00      0.00         1\n         596       0.00      0.00      0.00         0\n         597       0.00      0.00      0.00         1\n         598       0.00      0.00      0.00         1\n         599       0.00      0.00      0.00         1\n         600       0.00      0.00      0.00         1\n         601       0.00      0.00      0.00         0\n         602       0.00      0.00      0.00         0\n         603       0.00      0.00      0.00         1\n         604       0.00      0.00      0.00         0\n         605       0.00      0.00      0.00         0\n         606       0.00      0.00      0.00         1\n         607       0.00      0.00      0.00         0\n         608       0.00      0.00      0.00         1\n         609       0.00      0.00      0.00         1\n         610       0.00      0.00      0.00         1\n         611       0.00      0.00      0.00         0\n         612       0.00      0.00      0.00         1\n         613       0.00      0.00      0.00         1\n         614       0.00      0.00      0.00         0\n         615       0.00      0.00      0.00         0\n         616       0.00      0.00      0.00         1\n         617       0.00      0.00      0.00         1\n         618       0.00      0.00      0.00         0\n         619       0.00      0.00      0.00         0\n         620       0.00      0.00      0.00         0\n         621       0.00      0.00      0.00         0\n         622       0.00      0.00      0.00         1\n         623       0.00      0.00      0.00         0\n         624       0.00      0.00      0.00         1\n         625       0.00      0.00      0.00         1\n         626       0.00      0.00      0.00         0\n         627       0.00      0.00      0.00         1\n         628       0.00      0.00      0.00         0\n         629       0.00      0.00      0.00         1\n         630       0.00      0.00      0.00         0\n         631       0.00      0.00      0.00         1\n         632       0.00      0.00      0.00         0\n         633       0.00      0.00      0.00         1\n         634       0.00      0.00      0.00         1\n         635       0.00      0.00      0.00         0\n         636       0.00      0.00      0.00         2\n         637       0.00      0.00      0.00         1\n         638       0.00      0.00      0.00         1\n         639       0.00      0.00      0.00         1\n         640       0.00      0.00      0.00         1\n         641       0.00      0.00      0.00         0\n         642       0.00      0.00      0.00         0\n         643       0.00      0.00      0.00         1\n         644       0.00      0.00      0.00         0\n         645       0.00      0.00      0.00         0\n         646       0.00      0.00      0.00         0\n         647       0.00      0.00      0.00         0\n         648       0.00      0.00      0.00         0\n         649       0.00      0.00      0.00         0\n         650       0.00      0.00      0.00         1\n         651       0.00      0.00      0.00         0\n         652       0.00      0.00      0.00         0\n         653       0.00      0.00      0.00         1\n         654       0.00      0.00      0.00         1\n         655       0.00      0.00      0.00         0\n         656       0.00      0.00      0.00         1\n         657       0.00      0.00      0.00         1\n         658       0.00      0.00      0.00         1\n         659       0.00      0.00      0.00         0\n         660       0.00      0.00      0.00         1\n         661       0.00      0.00      0.00         1\n         662       0.00      0.00      0.00         1\n         663       0.00      0.00      0.00         0\n         664       0.00      0.00      0.00         0\n         665       0.00      0.00      0.00         1\n         666       0.00      0.00      0.00         1\n         667       0.00      0.00      0.00         0\n         668       0.00      0.00      0.00         0\n         669       0.00      0.00      0.00         0\n         670       0.00      0.00      0.00         0\n         671       0.00      0.00      0.00         1\n         672       0.00      0.00      0.00         1\n         673       0.00      0.00      0.00         0\n         674       0.00      0.00      0.00         0\n         675       0.00      0.00      0.00         0\n         676       0.00      0.00      0.00         1\n         677       0.00      0.00      0.00         1\n         678       0.00      0.00      0.00         1\n         679       0.00      0.00      0.00         0\n         680       0.00      0.00      0.00         0\n         681       0.00      0.00      0.00         0\n         682       0.00      0.00      0.00         0\n         683       0.00      0.00      0.00         0\n         684       0.00      0.00      0.00         0\n         685       0.00      0.00      0.00         1\n         686       0.00      0.00      0.00         0\n         687       0.00      0.00      0.00         1\n         688       0.00      0.00      0.00         1\n         689       0.00      0.00      0.00         0\n         690       0.00      0.00      0.00         1\n         691       0.00      0.00      0.00         1\n         692       0.00      0.00      0.00         1\n         693       0.00      0.00      0.00         0\n         694       0.00      0.00      0.00         1\n         695       0.00      0.00      0.00         0\n         696       0.00      0.00      0.00         0\n         697       0.00      0.00      0.00         0\n         698       0.00      0.00      0.00         0\n         699       0.00      0.00      0.00         0\n         700       0.00      0.00      0.00         1\n         701       0.00      0.00      0.00         1\n         702       0.00      0.00      0.00         1\n         703       0.00      0.00      0.00         0\n         704       0.00      0.00      0.00         1\n         705       0.00      0.00      0.00         1\n         706       0.00      0.00      0.00         0\n         707       0.00      0.00      0.00         1\n         708       0.00      0.00      0.00         0\n         709       0.00      0.00      0.00         1\n         710       0.00      0.00      0.00         0\n         711       0.00      0.00      0.00         1\n         712       0.00      0.00      0.00         1\n         713       0.00      0.00      0.00         0\n         714       0.00      0.00      0.00         0\n         715       0.00      0.00      0.00         0\n         716       0.00      0.00      0.00         1\n         717       0.00      0.00      0.00         1\n         718       0.00      0.00      0.00         0\n         719       0.00      0.00      0.00         1\n         720       0.00      0.00      0.00         0\n         721       0.00      0.00      0.00         1\n\n    accuracy                           0.14       833\n   macro avg       0.00      0.01      0.00       833\nweighted avg       0.13      0.14      0.13       833\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest.values.ravel(),p1,target_names=list(str(int) for int in range(0,722))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DecisionTreeClassifier()\n",
    "model2.fit(xtrain,ytrain)\n",
    "p2 = model2.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 1 0 0 1 2 0]\n [0 1 0 2 0 0 1]\n [0 1 2 0 0 1 1]\n [1 0 2 5 0 0 0]\n [1 1 1 1 3 0 0]\n [3 1 0 1 0 2 1]\n [0 1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(ytest,p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.17      0.20      0.18         5\n           1       0.17      0.25      0.20         4\n           2       0.40      0.40      0.40         5\n           3       0.56      0.62      0.59         8\n           4       0.75      0.43      0.55         7\n           5       0.40      0.25      0.31         8\n           6       0.25      0.50      0.33         2\n\n    accuracy                           0.38        39\n   macro avg       0.38      0.38      0.37        39\nweighted avg       0.43      0.38      0.39        39\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest.values.ravel(),p2,target_names=['0','1','2','3','4','5','6']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = GaussianNB()\n",
    "model3.fit(xtrain,ytrain)\n",
    "p3 = model3.predict(xtest)"
   ]
  },
  {
   "source": [
    "print(confusion_matrix(ytest,p3))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 376,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 3 0 0 2 0 0]\n [1 1 0 2 0 0 0]\n [0 1 4 0 0 0 0]\n [1 2 1 4 0 0 0]\n [1 3 0 0 1 0 2]\n [3 1 0 1 1 2 0]\n [0 1 1 0 0 0 0]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         5\n           1       0.08      0.25      0.12         4\n           2       0.67      0.80      0.73         5\n           3       0.57      0.50      0.53         8\n           4       0.25      0.14      0.18         7\n           5       1.00      0.25      0.40         8\n           6       0.00      0.00      0.00         2\n\n    accuracy                           0.31        39\n   macro avg       0.37      0.28      0.28        39\nweighted avg       0.46      0.31      0.33        39\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest.values.ravel(),p3,target_names=['0','1','2','3','4','5','6']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = KNeighborsClassifier()\n",
    "model4.fit(xtrain,ytrain)\n",
    "p4 = model4.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 2 0 1 2 0 0]\n [1 1 1 1 0 0 0]\n [0 2 1 1 0 0 1]\n [3 2 1 1 0 0 1]\n [1 2 2 0 1 0 1]\n [4 0 1 0 1 1 1]\n [1 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(ytest,p4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         5\n           1       0.11      0.25      0.15         4\n           2       0.17      0.20      0.18         5\n           3       0.20      0.12      0.15         8\n           4       0.25      0.14      0.18         7\n           5       1.00      0.12      0.22         8\n           6       0.00      0.00      0.00         2\n\n    accuracy                           0.13        39\n   macro avg       0.25      0.12      0.13        39\nweighted avg       0.32      0.13      0.15        39\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest.values.ravel(),p4,target_names=['0','1','2','3','4','5','6']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = LogisticRegression()\n",
    "model5.fit(xtrain,ytrain)\n",
    "p5 = model5.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 0 0 1 0 0 3]\n [0 0 0 3 0 0 1]\n [0 0 0 5 0 0 0]\n [2 0 0 5 0 0 1]\n [2 0 0 1 0 0 4]\n [2 0 0 4 0 0 2]\n [1 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(ytest,p5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.12      0.20      0.15         5\n           1       0.00      0.00      0.00         4\n           2       0.00      0.00      0.00         5\n           3       0.25      0.62      0.36         8\n           4       0.00      0.00      0.00         7\n           5       0.00      0.00      0.00         8\n           6       0.00      0.00      0.00         2\n\n    accuracy                           0.15        39\n   macro avg       0.05      0.12      0.07        39\nweighted avg       0.07      0.15      0.09        39\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest.values.ravel(),p5,target_names=['0','1','2','3','4','5','6']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-c355dad79a1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 242\u001b[1;33m     scores = parallel(\n\u001b[0m\u001b[0;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scorers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 score = scorer._score(cached_call, estimator,\n\u001b[0m\u001b[0;32m     88\u001b[0m                                       *args, **kwargs)\n\u001b[0;32m     89\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m                                                  **self._kwargs)\n\u001b[0;32m    211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0m\u001b[0;32m    213\u001b[0m                                                  **self._kwargs)\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "acc = np.mean(cross_val_score(model1, xtrain, ytrain, scoring='accuracy', cv=kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen11 = pd.DataFrame({'Model':'Random Forest',\n",
    "                      'Accuracy':[acc]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Model  Accuracy\n",
       "0  Random Forest  0.162065"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Random Forest</td>\n      <td>0.162065</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "allen11.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(cross_val_score(model2, xtrain, ytrain, scoring='accuracy', cv=kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen12 = pd.DataFrame({'Model':'Decision Tree',\n",
    "                      'Accuracy':[acc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(cross_val_score(model3, xtrain, ytrain, scoring='accuracy', cv=kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen13 = pd.DataFrame({'Model':'Naive Bayes',\n",
    "                      'Accuracy':[acc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(cross_val_score(model4, xtrain, ytrain, scoring='accuracy', cv=kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen14 = pd.DataFrame({'Model':'K-Nearest Neighbour',\n",
    "                      'Accuracy':[acc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(cross_val_score(model5, xtrain, ytrain, scoring='accuracy', cv=kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen15 = pd.DataFrame({'Model':'Logistic Regression',\n",
    "                      'Accuracy':[acc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 Model  Accuracy\n",
       "0        Random Forest  0.277425\n",
       "1        Decision Tree  0.288970\n",
       "2          Naive Bayes  0.274501\n",
       "3  K-Nearest Neighbour  0.199486\n",
       "4  Logistic Regression  0.184866"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Random Forest</td>\n      <td>0.277425</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Decision Tree</td>\n      <td>0.288970</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Naive Bayes</td>\n      <td>0.274501</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>K-Nearest Neighbour</td>\n      <td>0.199486</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Logistic Regression</td>\n      <td>0.184866</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 395
    }
   ],
   "source": [
    "al = pd.concat([allen11,allen12,allen13,allen14,allen15],axis=0).reset_index()\n",
    "al = al.drop('index',axis=1)\n",
    "al"
   ]
  },
  {
   "source": [
    "Using the K-Fold Analysis, a method for comparison, we can compare the algorithms based on the accuracies offered by them. Here, the highest accuracy offered is by Decision Tree ML algorithm, closely followed by Random Forest ML algorithm,for the given scenario and dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "name": "Nasscom Lab DA 3ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python38364bit570ee3c6a9ce451c90a4fee19734ed2d",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "5a2c2b1e8e21bd441da1d17902ec1befce5a77884cfd8dc3337a42ec4181cc68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}